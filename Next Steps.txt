- implement outline LFO (only volume of the original voice for now)
	# ig LFOs will have to go directly into the audio engine (not into the voices) so that there won't be any problems with polyphony and/or modulation later on
	# do reference the LFO in the voice though, but only advance its position while the voice isn't tailing off (-> no problems with polyphony later on)
	# render LFO waveform
	# implement changing the LFO's rate in the settings menu
	- make it possible to modulate other voices
		# change the RegionLfo's modulation function so that it also takes Voice* as an input
		# keep an array of voices in the LFO
			/ by default, only the associated region is in that list
		# overwrite the LFO's update function, so that it applies its update to all voices in the array, in the order they are contained in there
		# in the region's settings menu, show an area with a list of all the different regions (-> currenty equal to their voices, later on it will represent all the voices of the respective region)
		# make all items in that list checkable
		# when loading the menu, look up all the different regions (currently through the voices, later on through the voices' ids) and list them in the LFO's list
			# for a smoother workflow, it would be amazing if the items also took on their respective region's fillColour!
		# when checking/unchecking items from the list, update the LFO's voice array
			# fixed order: smallest region id to largest region id
		# bug: LFOs currently don't modulate their own associated region, only other regions
 !		- later: when deleting regions, make sure to adjust the LFOs' lists as well!
			- make the broadcaster a ChangeBroadcaster and add the settings menus as listeners -> notify when the LFOs list changes
	# create unipolar/bipolar LFO modes
		# unipolar: rewrites(!) the LFO's values to 0...1  ->  good for velocity modulation for instance
		# bipolar: rewrites(!) the LFO's values to -1...1  ->  good for pitch modulation for instance
	# implement other parameters to modulate
		!# there will most likely be one major problem with this: the voices' samples are probably not rendered in parallel; it's more likely that each voice renders 1 entire audio block in order
			(/) possible, but rather complicated fix: create an array of LFO modulation buffers in each voice. when an LFO updates another region's parameters, it instead writes an LFO modulation buffer (containing the values that it took on during the current block) and adds that block to the modulation buffer lists of every affected other voice as well as the parameter that the buffer should affect. while rendering, a voice will also parse the current sample of every buffer in its LFO modulation list and thus achieve the modulation sample by sample again. not sure how fast/slow this approach would be, though...
			# other idea: would it be possible for the synth to only render audio blocks one single sample at a time? that would also fix this problem (not sure if it would affect speed though)
				-> alright, apparently this works! will have to see whether this affects performance though. other than that, the only downside is that effects which take blocks to process cannot be used anymore (e.g. most filters, perhaps distortion?), but that should be fine, they probably aren't strictly needed or there might be workarounds
				?- as a workaround for block-based processing: maybe synth.renderNextBlock could only render the raw voice samples (incl. LFO adjustments), and afterwards there could be a method that triggers the block-based processing for all active voices. they only need to remember how their block-based effects' parameters were modulated during this block, though, which might further reduce performance...
		!# one more minor problem: how to handle parameters that are affected by multiple LFOs?
			(-) if every voice were to be handled sample by sample in parallel, it would probably be enough to change the respective setModulated[Parameter] methods to just multiply the modulated value by the passed amount, and to reset the modulated value to the base value at the beginning of each sample
				!# actually, making a variable that collects the multiplications (multiplier = 1.0 * mod1 * mod2 * ...) would be more consistent because parameter modifiers based on addition should be handled in the same manner (sum = 0.0 + mod1 + mod2 + ...) to avoid premature overflows (e.g. sum = 0.0 + 1.0 + 1.0 - 1.0 would return 0.0 when checking for overflows after every addition, but with all mods combined it would return 1.0)!
		# other voices' volume
			# also add a base volume slider to the settings menu (-60dB...+6dB)
		# voices' playback speed (incl. its own)
			# also add a base pitch slider to the settings menu (-60st...+60st -> since one octave doubles/halves the frequency, this corresponds to multiplication by 1/32...32, the formula being mult=2^(semis/12))
		# LFOs' rates (incl. its own)
		/ LFOs' modulation depths (incl. its own)
		# voices' playback positions (incl. its own)
			# would require adding a "slow update" mode to the LFO where it doesn't update during every single sample
			?- also add a base start position slider to the settings menu (0.0 ... 100.0 ?)
		# LFOs' update intervals (not very useful performance-wise, but should sound cool especially with LFOs that modulate pitch!)
		# LFOs' phase (= playback position) (incl. its own?)
			- adjust code that draws the LFO line on the image
	/ implement changing the LFO's modulation depth in the settings menu
 !		!- make it depend on the shape's size, actually
			- use the shape's area (bounds) in relation to that of the full image -> being >=2/3 of the image's area should result in full modulation depth
(# outline animations for the LFOs)
!# add a second column of toggle buttons to the LFO voice list that invert the modulation for that region
	-> this would be quite powerful since it enables call-and-response patterns (e.g. while one voice is loud another is quiet / while one voice is high another is low / ...)
	- this isn't as straightforward as it might seem since the modulation function is the same for all voices (whereas inversion would only be applied to some of the voices)!
		- solution: pass an Array<bool> to the lfo that says for which voices inversion should take place. when iterating over the voices, also iterate over that array and apply inversion on the go
			- is there a way to make this possible without if cases? for bipolar LFOs it would be enough to have an Array<int> with either +1 (not inverted) or -1 (inverted) and multiply the LFO value with one of these entries. but what about unipolar LFOs? inverting their values would be (1 - value), which can't really be put into an array
			-> use a second audio buffer containing the inverted waveform? this wouldn't save the if-case, but the following calculation...
		!# (probably) more efficient solution: instead of having just one modulation function, have one modulation function *per voice*
			#> at that point, it would also be easier to modulate different parameters of different voices (essentially making the list into *a mod matrix for every single region*), so that might actually be neat. but, to do that, the checkbox for the modulated parameter would have to also be moved into the listbox instead of being above it, which would require some more work
				# adjust CheckBoxList and CheckBoxListItem
				# Problem: how to handle Polarity? if there are different modulation functions, those are very likely to require different polarities...
					- naive solution: calculate the required polarity on the go -> too slow
					!# compromise: pre-calculate *both* polarities and select the one that's required... -> uses more memory, but saves multiplications
				# rework the modulationFunction/affectedVoices setup in RegionLfo
				# adjust the updateLfoParameter and copy Parameters methods in LfoEditor
	?/ each inversion button is only visible/enabled if the region has been selected
	# actually, an inversion button would be impractical - just make the inverted versions separate parameters
# (D)AHDSR envelope for voices
	# use this as a tester for a cleaner implementation of the state model maybe
	(-) if it's easy to do, also apply the same envelope to the region's LFO, not just the voice(s)
# split the RegionEditor into a different file
	-> possible now that i know how reference forwarding works
	-> create .h and .cpp for SegmentedRegion and for RegionEditor and put empty references to the other at the top of each header class
# split the LfoEditor into a different file
	-> possible now that i know how reference forwarding works
	-> create .h and .cpp for LfoEditor and for RegionEditor and put empty references to the other at the top of each header class
# DAHDSR: skip sustain state if sustain level is 0.0
	# would this cause problems in Voice? -> nope
# bipolar LFOs don't work as they intuitively should yet
	- currently: points closest to the focus point are at 0.0, points furthest away from the focus are either 1.0 or -1.0 (?)
	- how it should be: points closest to the focus point are -1.0, points furthest away are 1.0
	-> the bug was, that the reference point used wasn't actually the focus point *relative to the size of the region*, but actually the raw focus point - i.e. the focus point was assumed to always be in the top-left corner (between (0.0, 0.0) and (1.0, 1.0)...)
- improvements to processing speed
	-> implementing states in a cleaner fashion would probably help the most since it'd cut down on tons of if-cases
	!# implement states for Lfo and/or(?) RegionLfo
	!# get rid of std::function in RegionLfo
		/ neither juce::Array nor std::list nor juce::OwnedArray seem to be able to store function pointers for some weird reason...
			-> do some tests in a separate program
				- try arrays (-> would require lots of annoying dynamic memory re-allocation, so let's hope this isn't the only way to do it...)
				- try struct(/union?) containing the function pointer and make that the element of the list (-> less efficient?)
				?- just define functions in the class instead of using lambdas, and store pointers to those functions instead?
		?-> actually, juce::Array does seem to work, I believe the problem was that the switch case was skipped (wrong variable...) and that led to the error message
	!# get rid of std::function in Voice
		# create a cpp file and simply use a pointer to the RegionLfo instead (will currently require an additional if case, but that will be addressed through the Voice states later)
	!#(?) add a parameter "update time" (or so - just don't use frequency since it needs to be in s, not 1/s) to the Lfo class -> adjustable by the user, 0.0s (real-time updates) explicitly allowed!
		# this does require another if case, but since branch prediction should be easy in this case (simple decrements will occur more often than updates), it should be fine-ish. the true performance increase will occur in combination with the ModulatableParameter class
			(concerning the branch prediction, see https://igoro.com/archive/fast-and-slow-if-statements-branch-prediction-in-modern-processors/ )
		# for a slight performance boost for the 0s case, make that into one or more separate RegionLfo state(s)
		-> NOTE: this won't be audible until the ModulatableParameter class has been implemented (see below)
	!# add a new generic class ModulatableParameter. this class contains the parameter's base value as well as the current modulated value. it also contains a modulator list to which LFOs can add(/remove) themselves
		!# important trick: the class has states which show whether any modulator has updated its value. the new value is only calculated (-> potentially lots of multiplications) when something tries to access the modulated value - instead of updating it every time any modulator updates (which would be much slower). using states (instead of a bool and an if) saves 1 if per sample per modulated value per voice/LFO, so they're crucial
		# adding new modulators: the modulated value creates a new entry (generic value - float or double in this case) in its list of modulators. the modulator (LFO) gets a pointer to that entry (-> quick update) and also saves a reference to the ModulatableParameter class to call a method "hasUpdated" (or so) whenever the modulator updates the value
		# exchange modulation functions for pointers to modulated parameters in RegionLfo, adjust adding/removing modulations (those will now handle defining lfoEvalFuncPt for ModulatableParameter!)
		# when RegionLfo updates, only call signalModulatorUpdated() in each ModulatableParameter instead of all the calculations until now
		# add methods to Voice/RegionLfo for getting pointers to their ModulatableParameter members (required for registering/unregistering modulations in RegionLfo)
		# use ModulatableParameter for Voice parameters
		# use ModulatableParameter for RegionLfo parameters
		!# currently throws a compile error. might be a circular reference problem, but i'm also beginning to suspect some kind of implementation error in ModulatableParameter that intellisense didn't catch (it failed to recognise a non-existing variable last time i checked - might have smth to do with the generics...)
			# plan A: try commenting out every method in ModulatableParameter and then building -> if it builds successfully, the problem lies somewhere in ModulatableParameter!
				- did not fix it
			# plan B: change RegionLfo back so that it doesn't use ModulatableParameter for its own frequency anymore. if it builds... well then at least it's clear where the problem was, maybe it helps. if it doesn't build, reload the last commit for a quicker rollback
				- did not fix it. it doesn't recognise the <double> parameter for the remaining ModulatableParameters then (again still a sign that the cyclic reference doesn't compile...)
			# plan C: apparently, .cpp implementations of a generic class are not necessary or even wrong! -> define ModulatableParameter fully in the header file and check whether that solves it!
				see https://stackoverflow.com/questions/62359169/c-generic-class-why-do-i-need-cpp-file
				- did not fix it
			# plan D: apparently, compiling individual cpp files might give better (or at least less cluttered) error messages -> try it for a few cpp files and see if anything becomes clearer
				-> maybe AudioEngine needs a cpp? -> nope, didn't change anything (probably not a bad thing to leave it in though since compiling individual files is actually pretty neat)
					- actually, it *did* fix a (minor) compilation error in SegmentedRegion.cpp, so that's good
				-> it might be necessary to make the ModulatableParameters in RegionLfo into pointers: https://readforlearn.com/implicit-instantiation-of-undefined-template-when-forward-declaring-template-class/
					(or ModulatableAdditiveParameter<double> has to be defined somewhere before --> an alternative would be to predefine ModulatableAdditiveParameter as being a subclass of ModulatableParameter<double> again)
			/ plan D: write out the cpp files with expanded headers for ModulatableParameter, RegionLfo and Voice. is any one of them missing a forward reference? do they have the requirements to use methods if they need to do so?
				see https://isocpp.org/wiki/faq/misc-technical-issues#forward-decl-members (scroll up a little, anchor doesn't work properly),
				    https://stackoverflow.com/questions/625799/resolve-build-errors-due-to-circular-dependency-amongst-classes
			/ plan E: remove ModulatableParameter use entirely from RegionLfo, Voice, LfoEditor and AudioEngine. If it doesn't build, the error lies somewhere in the code of ModulatableParameter
				(#) maybe this could also be done by only compiling ModulatableParameter? is it possible to do that?
					- apparently that's possible, but it didn't fix it it still tries to compile RegionLfo...
			/ plan F: try running the connections over AudioEngine, i.e. ModulatableParameters exist only in AudioEngine instead of as class members - would that work? And even if it does, would it be efficient enough?
		# if everything works, clean up commented code in RegionLfo and Voice
	!(#) implement states for Voice
 !		!- technically, changing the wavefile of the osc member isn't handled yet
	# switch to function templates or function pointers instead of std::function -> see https://stackoverflow.com/questions/25848690/should-i-use-stdfunction-or-a-function-pointer-in-c
		https://vittorioromeo.info/index/blog/passing_functions_to_functions.html
		https://stackoverflow.com/questions/43948240/sfinae-failing-when-evaluating-a-constexpr-in-a-template-parameter/43949301?noredirect=1#comment74933533_43949301
		https://stackoverflow.com/questions/28746744/passing-capturing-lambda-as-function-pointer/28746827#28746827
		https://stackoverflow.com/questions/9054774/difference-between-stdfunction-and-a-standard-function-pointer/9054802#9054802
		-> function pointers were the way to go in this case
	- make use of certain keywords
		- noexcept: tells the compiler that the method won't throw any exceptions -> more optimisations possible
		- inline / __forceinline: tell the compiler that the method should be inlined
			- methods that are defined in the header of a file are implicitly inline; if they are defined in the cpp, inline can be added at the beginning. forceinline should be used sparingly as too much inlining may actually hurt performance due to larger binaries and paging
		# final (classes)
			- for the state implementations
			- see https://devblogs.microsoft.com/cppblog/the-performance-benefits-of-final-classes/
		/ register keyword?
			- probably overkill, the compiler should do this automatically already...
		- when to use references and when not?
	# correctly using const pointers (vs. pointer consts and const pointer consts) might also be useful for making things cleaner (though not necessarily faster)
		- see https://stackoverflow.com/questions/1143262/what-is-the-difference-between-const-int-const-int-const-and-int-const
		- for functions, see also https://stackoverflow.com/questions/751681/meaning-of-const-last-in-a-function-declaration-of-a-class
	# correctly using references could also improve some things (e.g. using references instead of pointers for state implementations and regions' voices, LFOs etc. might be worth thinking about)
		- https://www.tutorialspoint.com/cplusplus/cpp_references.htm
		- note also: https://stackoverflow.com/questions/51705967/advantages-of-pass-by-value-and-stdmove-over-pass-by-reference
		- first comment of the first reply here is also important: https://stackoverflow.com/questions/21215409/does-c-pass-objects-by-value-or-reference
			- for a more direct example: https://stackoverflow.com/questions/9293674/can-we-reassign-the-reference-in-c#9293732
	- declare methods as const if they don't change member variables: https://stackoverflow.com/questions/24500909/passing-class-reference-to-function
# bug: LFO line doesn't update when LFO doesn't modulate anything
	- a RegionLfoState wasn't set up correctly, that's all
# bug: the LFO line doesn't keep updating while the voice is tailing off (-> just create a bool variable isPlaying in Voice that's checked for that purpose)
# add visual feedback for update rate
	!# idea: adjust update rate of the *line drawing* accordingly! this is a win-win, because it provides feedback and even reduces the CPU usage further!
/ is there a way to make it so that modulation of other regions remains at the current modulation value even when the region modulating it stops playing?
	-> example: currently, if region 1 modulates region 2's volume, the modulation stops after region 1 stops playing (i.e. region 2 plays with its base volume - not the base volume multiplied with the LFO value of region 1 that was last measured). is there a way to apply the LFO's modulation independent from a region playing?
	- idea: maybe advance all LFOs *before* rendering all next synth samples? would that change anything/much?
		!- this would also have the advantage that it wouldn't require a Voice (i.e. an audio file) for a region's LFO to work
		- problem: this would require either the audio engine or the LFOs to keep track of which LFOs are playing, which could require additional if-cases every sample...
			!- solution part 1: when implementing the DAHDSR envelope for the LFOs, it would require them to keep track of whether or not they are playing anyway -> two birds with one stone!
			!- solution part 2: after implementing states for the LFOs and the DAHDSR, there might as well be "Playing" and "Not Playing" states, converting the additional if cases to quick array accesses
			-> definitely doable! now the only remaining question is whether evaluating the LFOs before rendering the voices significantly changes the sound
	- idea 2: maybe don't use a single variable to accumulate modulations. instad, use a list of modulation values with are multiplied/summed during every sample. when an LFO starts modulating a value, its value is inserted into the list and updated after every sample - but only removed when the LFO is deleted or starts modulating a different value. downside: more operations during every sample
	#-> this is now already the case because of the ModulatableParameter class
# implement more LFO-modulatable parameters
# update LFO menu (might not be necessary anymore depending on what has been done at the point that this is next)
# bug: LFO line doesn't update again when the LFO doesn't modulate anything
# bug: the LFO continuously updates after the region has been drawn despite not being played. stops after the region has been played once.
# states for SegmentedRegion
	# when registering a new region in AudioEngine, also generate its RegionLfo and Voice instances! the region will then update these LFO's/voices' wavetable as soon as the user selects it. until then allow to play the region, but only with the LFO active
		# in that case, checkboxes for regions that are missing their wavefile should proooobably stay disabled? (i don't think registering modulators would break anything though)
		# the bigger "problem" would be that the Voice class would need new methods to initialise its osc member, and these updates also need to be handled in the VoiceState members, which might require even more methods...
			- the advantage of this would be that the buffers in the osc member should be exchangable anyway, so...
		#? make sure that when changing the wavefiles of the voices or the LFO, that the new methods for doing so are used!
		# bug: region's background isn't drawn the first time it appears
		# bug: the regions' colours aren't displayed in the region editor anymore
  !		!- bug: sometimes, after completing a region, the SegmentableImage triggers startNewSubpath of the path object somewhere resulting in an exception
			/ it might've been the incorrectly(?) implemented iterator in the tryDeleteLastNode method. it might be fixed now
				- nope, that wasn't it...
			- now that i know how to display the callstack, it should be easier to fix if it occurs again
		# bug: the regions remain toggleable in edit mode
	# implement transitionToState method
	# include states' specialised methods in SegmentedRegion
# states for SegmentableImage
	# create SegmentableImageStateIndex
	# create states
	# implement states in SegmentableImage class
# fix memory leaks that occur when closing the program
	!- new evidence: the leak also occurs when switching the SegmentableImageStateIndex back to empty!
		/ i'm beginning to think it might be the SegmentedRegion destructor that doesn't correctly destroy everything yet
		/ idea: LFOs aren't unsubscribed from their modulated parameters when they're deleted, they just clear the lists of the parameters they modulate!
		!/ it's the ModulatableParameter destructor! the "delete state" statements sometimes throw exceptions - why?
			/ idea: maybe the states aren't being initialised? that would mean that in some *constructor*, some parameters aren't initialised (or are using the wrong contructor)!
			-> nope, actually it isn't.
		-> now that i finally know how to display the callstack, it's simple... calling the Lfo destructor in the RegionLfo destructor was the problem. this could've been fixed a lot faster man... but i'm still glad it's finally done and gone.
	- theory 1: some classes just don't destroy their contents correctly
	- theory 2: the leaks happen in certain states of SegmentableImage (maybe editable, definitely in playable)
	- theory 3: some leaks happen because AudioEngine is still rendering blocks while some (playing) parts are being deleted
		-> fix 1: stop audio engine when pressing the close button, then delete all contents
		-> fix 2: implement locks (probably good idea in the long run, but perhaps too much work for this one fix...)
# calculate a region's colour from the pixels behind it
	# use the median of all the colours
	# also increase the region's transparency by 10-20% -> makes it so that the region maintains some of the background's textures instead of being just a solid colour, should look more professional
# draw LFO line with a black outline
# draw segmented region with a contrasting outline
- bug: when closing the window with a lot of regions on it, some of the parameters end up containing invalid modulators, thus causing an exception
	- pretty sure some LFOs aren't correctly unsubscribed when LFOs/Voices/? are deleted
- check whether it's possible to resize VSTs
- make it possible to delete regions
	- to handle all the audio parameters, create a method in the *audio engine*(!) that deletes all voices with the region's id from the LFOs' voice lists, and then all of those voices from the synth
# bug: samplesUntilUpdate of LFO should be reset to 0 after a voice stops (otherwise, the LFO line will be drawn with a temporal offset...)
# bug: ^- the playback position should do so as well - does it?
# bug: LFO line doesn't recognise modulations of the RegionLfo's update interval
	- idea: get samplesUntilUpdate from the respective LFO every time the LFO line updates and update the rate that way
		!- IMPORTANT: do NOT call the modulated value of the update rate parameter! that would mess with its modulation!
# bug: LFO line doesn't recognise modulations of the RegionLfo's phase
	- reason: getPhase is being called, which outputs the *base value* of the phase, not the modulated value
	- problem: calling the modulated value would mess with the modulation!
	-> solution: since this is a problem that'll only occur once (at least presumably) and not in other instances of ModulatableParameter, it should be fine to just create a new variable that stores the latest modulated phase, and a getter method for that variable 
# add an option to make the pitch shift quantised to either semitones or a normal scale (might be possible to do with the interpolation tables?)
	- this would add SO MUCH since actual, non-chaotic *melodies* could be created with it using a region that pitch mods itself at a slow interval and a second region that alters the first region's update rate or LFO rate
- implement play path(s)
- serialisation




- improve drawing algorithm using image information
	- differentiate between left and right clicks: left clicks use the automated outline finder, right clicks simply draw straight lines like they do now -> more flexible
- fix some bugs/things that would cause problems with unknowing users
	- since regions currently only keep their voice's index, errors would occur if regions that were created earlier than that region were deleted
		-> fix: when implementing polyphony, voices will have a certain variable that refers to their region. simply delete only voices with the corresponding variable value -> two birds with one stone
	- voices would currently keep playing while toggled on and switching to editing -> region could be deleted while playing -> errors in audio buffer!
		-> fix: tell the synth to stop all notes without tailoff when switching from playing to any other state
		- actually, it's kiiiinda nice to be able to edit an LFO's parameters while the sound is still playing... maybe there's a way to only force a stop when selecting a new audio file?
	- when setting a region to togglable, they also toggle in editing mode
		-> fix: only update their toggleable state when switching to playing
		- see above bug; maybe make an exception for editing mode (but switch all regions to off when switching back to playing mode maybe)
	- make it so that regions can only be created when at least 3 points have been added to the screen (might already be in the code)
		(!)- bonus: make it so that regions can only be created if the points aren't on a line
	- safer audio file loading (see juce tutorial)
(- panning setting for each region)
- implement states the cleaner way: using the actual state model (i.e. using interfaces)
	?- for PluginEditor
	- for SegmentableImage
	- for SegmentedRegion
	# for Lfo (updating the parameter while wavetable isn't set currently takes up ressources every sample)
	# for Voice/Sound probably (again, ressources are taken up while the audio data hasn't been loaded yet)
!- allow for 2-voice-polyphony
	- add *2* voices *and 1 sound* per region
	- add a variable to the voice and oscillator class that represents the region, and tell it that it can only play sounds if its variable corresponds to that of the oscillator
		- add a counter variable (uint should suffice) to the audio engine. this variable is incremented every time a new region is created. the regions take on the current value of the counter when they are created. -> unique ID
		- display the region's ID in the title of the region's settings menu!
		- all juce::Component objects should have a methods getComponentID/setComponentID -> use those
	- instead of using Voice.startNote, use synth.noteOn to play sounds
		- maybe overwrite this somehow? how will the synth know which sound to play?
			!- maybe make it so the sound can only play one specific MIDI note, and the region plays that specific note
				- this has the added benefit that implementing MIDI support for the instrument will be easier - just make that MIDI note adjustable in the region editor!
- add some kind of information button that displays key mappings for each mode (e.g. using backspace to delete points while in drawing mode)
(- add playback modes for the voices: Normal (Forward), Oneshot, Forward-Backward, Backward-Forward, Backward)
!- add an option to quantise the start/stop timings of voices to certain note values corresponding to the DAW's BPM
	- this would be an amazing quality of life change, but idk how easy this would be... i know that the DAW's BPM should be contained in some MIDI signals, but idk where or when or how to evaluate them to achieve synchronisation
	- did smth similar in Langton's Ant Sequencer, and it's not quiiiite so easy to do, sadly
- set help texts for all components
	- there should already be a method setHelpText for all Component members
- option to set an LFO's rate to that of its associated region's sound
- button to reset an LFO's phase
- perhaps modulate a region's LFO depth with its AHDSR modulator (whether or not it's possible to modulate LFO depth otherwise)
- add Parameters for the DAW
